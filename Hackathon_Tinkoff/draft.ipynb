{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb88b34-5ebb-465e-9e9a-a6e0d21e8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f08f9a-89bc-447b-9090-b740fd28d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "communications = pd.read_csv('communications.csv', sep=';')\n",
    "course_employee_sms = pd.read_csv('course_employee_sms.csv', sep=';')\n",
    "employees = pd.read_csv('employees.csv', sep=';')\n",
    "courses_passing = pd.read_csv('courses_passing.csv', sep=';')\n",
    "courses_info = pd.read_csv('courses_info.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69ad682-2f34-48af-9d38-31d0b7cd235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "communications = pd.read_csv('communications.csv', sep=';')\n",
    "course_employee_sms = pd.read_csv('course_employee_sms.csv', sep=';')\n",
    "employees = pd.read_csv('employees.csv', sep=';')\n",
    "courses_passing = pd.read_csv('courses_passing.csv', sep=';')\n",
    "courses_info = pd.read_csv('courses_info.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2322478c-5823-4808-bfbd-945b41303385",
   "metadata": {},
   "outputs": [],
   "source": [
    "communications['communication_dt'] = pd.to_datetime(communications['communication_dt'])\n",
    "courses_passing['start_dt'] = pd.to_datetime(courses_passing['start_dt'])\n",
    "courses_passing['last_activity_dt'] = pd.to_datetime(courses_passing['last_activity_dt'])\n",
    "courses_passing['end_dt'] = pd.to_datetime(courses_passing['end_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5bf4d3-34ce-4a8d-b02b-04c98c401b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "communications_prep = communications.groupby(['employee_id','communication_dt'])['communication_score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c91ad4-745b-44af-9222-baa100ff4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = communications_prep.merge(courses_passing[courses_passing.pass_frac==1], how='left', on='employee_id')\n",
    "res = res[res['course_id'].notnull()]\n",
    "res['before_course'] = res[['end_dt', 'communication_dt']].apply(lambda x: 1 if x.end_dt < x.communication_dt else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203fef2f-8669-4eb1-9fc0-ab97203ca814",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5 = res.groupby(['course_id','before_course','employee_id'])['communication_score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b02ceaea-c1c3-4cbb-9b4c-5d0e32e282c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test6 = test5[test5['before_course']==1].merge(test5[test5['before_course']==0], how='left', on=['employee_id','course_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27737a7b-58c0-49f7-91ec-511ff06117cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test6['diff']=test6['communication_score_x']-test6['communication_score_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25cfda4e-a10e-4fdf-96e8-1db678e3e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "test6['target'] = test6['diff'].apply(lambda x: 1 if x>2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f224993-f5b3-4351-a5c4-7486e1dcd20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8404, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09050ff-5ae2-4ab3-8a83-fb9450b65f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57dadc45-7309-4e7a-a6ce-aadaad399ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = test6[['course_id','employee_id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1cc3ba4-6797-42c9-9179-488ecb3b932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seles\\AppData\\Local\\Temp\\ipykernel_792\\1947827498.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.employee_id = le_user.fit_transform(new_df.employee_id.values)\n",
      "C:\\Users\\seles\\AppData\\Local\\Temp\\ipykernel_792\\1947827498.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.course_id = le_movie.fit_transform(new_df.course_id.values)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le_user = preprocessing.LabelEncoder()\n",
    "le_movie = preprocessing.LabelEncoder()\n",
    "new_df.employee_id = le_user.fit_transform(new_df.employee_id.values)\n",
    "new_df.course_id = le_movie.fit_transform(new_df.course_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9931c89b-3a6d-466c-b759-609d1b2d85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(new_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a459f1f1-786a-4f57-a9d9-4447127cbc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6723, 3]), torch.Size([1681, 3]), tensor([  89., 1290.,    0.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# количество пользователей и продуктов\n",
    "n_users = new_df['employee_id'].nunique()\n",
    "n_items = new_df['course_id'].nunique()\n",
    "\n",
    "# преобразование набора данных в тензор для использования в PyTorch\n",
    "train_data = torch.FloatTensor(train_df.values)\n",
    "test_data = torch.FloatTensor(test_df.values)\n",
    "\n",
    "train_data.shape, test_data.shape, test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa2b7c97-c8ed-4c34-b416-51eaf09428dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 57, 370,   0]])\n",
      "tensor(-0.1310, grad_fn=<SqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seles\\AppData\\Local\\Temp\\ipykernel_792\\1206442382.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = torch.tensor(train_data, dtype=torch.long)\n",
      "C:\\Users\\seles\\AppData\\Local\\Temp\\ipykernel_792\\1206442382.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = torch.tensor(test_data, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor(train_data, dtype=torch.long)\n",
    "test_data = torch.tensor(test_data, dtype=torch.long)\n",
    "\n",
    "# модель\n",
    "class RecommenderNet(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=50):\n",
    "        super().__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_embedding = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.fc1 = torch.nn.Linear(n_factors*2, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 1)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_ids = x[:, 1].unsqueeze(1)\n",
    "        item_ids = x[:, 0].unsqueeze(1)\n",
    "\n",
    "        user_embedding = self.user_embedding(user_ids)\n",
    "        item_embedding = self.item_embedding(item_ids)\n",
    "\n",
    "        x = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "n_users = train_data[:, 1].max() + 1\n",
    "n_items = train_data[:, 0].max() + 1\n",
    "\n",
    "model = RecommenderNet(n_users, n_items, n_factors=50)\n",
    "# прогнозы\n",
    "print(train_data[0].unsqueeze(0))\n",
    "prediction = model(train_data[0].unsqueeze(0))\n",
    "print(prediction.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e799e3a3-dfb5-413a-8649-b15dfdd22811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оптимизатор и функция потерь\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "021c3226-3f29-4ca0-842e-15c14a9d0cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6723, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dea8ef6-d6e9-46fd-91bd-6f3bf9b60387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train RMSE: 0.00776971531821282\n",
      "Epoch: 2 Train RMSE: 0.007230829279816047\n",
      "Epoch: 3 Train RMSE: 0.007120555787702825\n",
      "Epoch: 4 Train RMSE: 0.007061650337794295\n",
      "Epoch: 5 Train RMSE: 0.00724552183005187\n",
      "Epoch: 6 Train RMSE: 0.007192731507762374\n",
      "Epoch: 7 Train RMSE: 0.007138415780012419\n",
      "Epoch: 8 Train RMSE: 0.007068753739618254\n",
      "Epoch: 9 Train RMSE: 0.006934993829415685\n",
      "Epoch: 10 Train RMSE: 0.006863840247609224\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_data)\n",
    "    loss = criterion(outputs.squeeze(), train_data[:, 2].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # train RMSE \n",
    "    train_rmse = np.sqrt(train_loss / len(train_data))\n",
    "    print(\"Epoch:\", epoch+1, \"Train RMSE:\", train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a66d9c6-ed40-4894-b28e-a8ebe3e3fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1681, 3])\n",
      "torch.Size([1681, 1, 1])\n",
      "Test RMSE: 0.013537137449460853\n"
     ]
    }
   ],
   "source": [
    " # test RMSE \n",
    "test_loss = 0.0\n",
    "print(test_data.shape)\n",
    "outputs = model(test_data)\n",
    "print(outputs.shape)\n",
    "\n",
    "loss = criterion(outputs.squeeze(), test_data[:, 2].float())\n",
    "test_loss += loss.item()\n",
    "\n",
    "test_rmse = np.sqrt(test_loss / len(test_data))\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51520c-1fec-4436-aa97-cc2b4b44124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# кол-во курсов, которые следует рекомендовать\n",
    "top_k = 10\n",
    "\n",
    "# матрицы характеристик пользователя и элемента\n",
    "user_embeddings = model.user_embedding.weight.detach().numpy()\n",
    "item_embeddings = model.item_embedding.weight.detach().numpy()\n",
    "\n",
    "# функция рекомендации\n",
    "def recommend(user_id):\n",
    "    # получение курсов с высокими прогнозируемыми рейтингами из курсов, отличных от тех, которые прошел пользователь.\n",
    "    user_items = new_df[new_df['employee_id'] == user_id]['course_id'].unique()\n",
    "    user_embedding = user_embeddings[user_id-1]\n",
    "    scores = np.dot(item_embeddings, user_embedding)\n",
    "    scores = np.array([(i+1, score) for i, score in enumerate(scores)])\n",
    "    scores = scores[~np.isin(scores[:, 0], user_items)]\n",
    "    scores = scores[scores[:, 1].argsort()[::-1]]\n",
    "    top_k_items = scores[:top_k, 0].astype(int)\n",
    "    return top_k_items\n",
    "\n",
    "# вывод примера\n",
    "user_id = 1\n",
    "recommended_items = recommend(user_id)\n",
    "print(f\"User {user_id} список рекомендуемых курсов: {recommended_items}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
